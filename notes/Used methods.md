# Methods used
## Models
- K-Bert
- RoBERTa
- ALBERT
- XLNet
- Ensembles
- K-GAT
- Siamese models
- CNN
- Attention LSTM
- BiLSTM
- BiGRU
## Techniques
- Pretraining on external corpora: OMCS, NLI, STS, SWAG
- Back-translation augmentation
- Text-to-image features
- ConceptNet embeddings
- ConceptNet for constructing an additional dataset
- Preprocessing: SpaCy's NER
- Masking the most important word

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer-experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_rNAaM3RjfT"
      },
      "source": [
        "# Different transformer-based models experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9CxTsJDY42-"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "his_yclCRjSe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZKzuGtfycJA"
      },
      "source": [
        "# Position into correct google drive folder - this may vary!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzD4DI_WRiOI"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/fer-tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGVjL1Krygjx"
      },
      "source": [
        "# Install required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNSEn5_LTC-L"
      },
      "source": [
        "!pip install -q pytorch_lightning\n",
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH1SQIVeyons"
      },
      "source": [
        "# Import required modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHW7VwogTEsb"
      },
      "source": [
        "from importlib import reload\n",
        "import src.modelss\n",
        "import my_scripts.data\n",
        "reload(src.modelss)\n",
        "reload(my_scripts.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaTuHsIMTGFN"
      },
      "source": [
        "from src.modelss import TransformerBasedClassifier\n",
        "from src.tokenizers import TransformerTokenizer\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from my_scripts.data import ComVEDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68XhFPwQysZA"
      },
      "source": [
        "# Initialize hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XcaduifTK5r"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8\n",
        "# NAMES = ['bert', 'albert', 'roberta', 'electra']\n",
        "NAMES = ['electra']\n",
        "# AUG_SIZES = [5000, 10000]\n",
        "AUG_SIZES = [5000]\n",
        "DROP = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g52fmTtMywpU"
      },
      "source": [
        "# Position into some subfolder because of Pytorch Lightning and its logging system..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZUI95DPcnsF"
      },
      "source": [
        "%cd Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMLOOIJsy5ut"
      },
      "source": [
        "# Training loop and testing on evaluation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s2YYYBHTQDw"
      },
      "source": [
        "for name in NAMES:\n",
        "    tokenizer = TransformerTokenizer(name=name)\n",
        "    for size in AUG_SIZES:\n",
        "        train_ds, val_ds, test_ds = ComVEDataset.gpt2_lm_plain(data_folder='/content/gdrive/MyDrive/git/data',\n",
        "                                                               training_x='GPT2_data_final_prod.csv',\n",
        "                                                               training_y='GPT2_answers_final_prod.csv',\n",
        "                                                               x_transforms=[tokenizer], \n",
        "                                                               aug_size=0)\n",
        "        train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_ds, batch_size=len(val_ds))\n",
        "        test_dataloader = DataLoader(test_ds, batch_size=len(test_ds))\n",
        "        training_steps = len(train_dataloader) * EPOCHS\n",
        "        model = TransformerBasedClassifier(name=name, \n",
        "                                           drop=DROP, \n",
        "                                           lr=4e-5, \n",
        "                                           weight_decay=0.01, \n",
        "                                           training_steps=training_steps)\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            monitor = 'val_loss',\n",
        "            dirpath = 'checkpoint/',\n",
        "            filename = 'best-model-' + name,\n",
        "            save_top_k = 1\n",
        "        )\n",
        "        trainer = pl.Trainer(max_epochs=EPOCHS, \n",
        "                             gpus=1, \n",
        "                             progress_bar_refresh_rate=20, \n",
        "                             callbacks=[])\n",
        "        trainer.fit(model, train_dataloader, val_dataloader)\n",
        "        l, a = model.get_best_loss_and_acc()\n",
        "        model = TransformerBasedClassifier.load_from_checkpoint(checkpoint_callback.best_model_path,\n",
        "                                                                name=name,\n",
        "                                                                drop=DROP,\n",
        "                                                                append_name=f'aug_size={size}')\n",
        "        model.val_loss, model.val_acc = l, a\n",
        "        trainer.test(model, test_dataloader)\n",
        "    !rm -rf checkpoint/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}